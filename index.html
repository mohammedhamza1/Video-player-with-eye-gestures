<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="styles.css">

  </head>
  <body>
    <div class="page-wrapper">
      <div class="video-container paused" data-volume-level="high">
        <img class="thumbnail-img">
        <div class="video-controls-container">
          <div class="timeline-container">
            <div class="timeline">
              <img class="preview-img">
              <div class="thumb-indicator"></div>
            </div>
          </div>
          <div class="controls">
            <button class="play-pause-btn">
              <svg class="play-icon" viewBox="0 0 24 24">
                <path fill="currentColor" d="M8,5.14V19.14L19,12.14L8,5.14Z" />
              </svg>
              <svg class="pause-icon" viewBox="0 0 24 24">
                <path fill="currentColor" d="M14,19H18V5H14M6,19H10V5H6V19Z" />
              </svg>
            </button>
            <div class="volume-container">
              <button class="mute-btn">
                <svg class="volume-high-icon" viewBox="0 0 24 24">
                  <path fill="currentColor"
                    d="M14,3.23V5.29C16.89,6.15 19,8.83 19,12C19,15.17 16.89,17.84 14,18.7V20.77C18,19.86 21,16.28 21,12C21,7.72 18,4.14 14,3.23M16.5,12C16.5,10.23 15.5,8.71 14,7.97V16C15.5,15.29 16.5,13.76 16.5,12M3,9V15H7L12,20V4L7,9H3Z" />
                </svg>
                <svg class="volume-low-icon" viewBox="0 0 24 24">
                  <path fill="currentColor"
                    d="M5,9V15H9L14,20V4L9,9M18.5,12C18.5,10.23 17.5,8.71 16,7.97V16C17.5,15.29 18.5,13.76 18.5,12Z" />
                </svg>
                <svg class="volume-muted-icon" viewBox="0 0 24 24">
                  <path fill="currentColor"
                    d="M12,4L9.91,6.09L12,8.18M4.27,3L3,4.27L7.73,9H3V15H7L12,20V13.27L16.25,17.53C15.58,18.04 14.83,18.46 14,18.7V20.77C15.38,20.45 16.63,19.82 17.68,18.96L19.73,21L21,19.73L12,10.73M19,12C19,12.94 18.8,13.82 18.46,14.64L19.97,16.15C20.62,14.91 21,13.5 21,12C21,7.72 18,4.14 14,3.23V5.29C16.89,6.15 19,8.83 19,12M16.5,12C16.5,10.23 15.5,8.71 14,7.97V10.18L16.45,12.63C16.5,12.43 16.5,12.21 16.5,12Z" />
                </svg>
              </button>
              <input class="volume-slider" type="range" min="0" max="1" step="any" value="1">
            </div>
            <div class="duration-container">
              <div class="current-time">0:00</div>
              /
              <div class="total-time"></div>
            </div>
            <button class="captions-btn">
              <svg viewBox="0 0 24 24">
                <path fill="currentColor"
                  d="M18,11H16.5V10.5H14.5V13.5H16.5V13H18V14A1,1 0 0,1 17,15H14A1,1 0 0,1 13,14V10A1,1 0 0,1 14,9H17A1,1 0 0,1 18,10M11,11H9.5V10.5H7.5V13.5H9.5V13H11V14A1,1 0 0,1 10,15H7A1,1 0 0,1 6,14V10A1,1 0 0,1 7,9H10A1,1 0 0,1 11,10M19,4H5C3.89,4 3,4.89 3,6V18A2,2 0 0,0 5,20H19A2,2 0 0,0 21,18V6C21,4.89 20.1,4 19,4Z" />
              </svg>
            </button>
            <button class="speed-btn wide-btn">
              1x
            </button>
            <button class="mini-player-btn">
              <svg viewBox="0 0 24 24">
                <path fill="currentColor"
                  d="M21 3H3c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h18c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H3V5h18v14zm-10-7h9v6h-9z" />
              </svg>
            </button>
            <button class="theater-btn">
              <svg class="tall" viewBox="0 0 24 24">
                <path fill="currentColor"
                  d="M19 6H5c-1.1 0-2 .9-2 2v8c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V8c0-1.1-.9-2-2-2zm0 10H5V8h14v8z" />
              </svg>
              <svg class="wide" viewBox="0 0 24 24">
                <path fill="currentColor"
                  d="M19 7H5c-1.1 0-2 .9-2 2v6c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V9c0-1.1-.9-2-2-2zm0 8H5V9h14v6z" />
              </svg>
            </button>
            <button class="full-screen-btn">
              <svg class="open" viewBox="0 0 24 24">
                <path fill="currentColor" d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z" />
              </svg>
              <svg class="close" viewBox="0 0 24 24">
                <path fill="currentColor" d="M5 16h3v3h2v-5H5v2zm3-8H5v2h5V5H8v3zm6 11h2v-3h3v-2h-5v5zm2-11V5h-2v5h5V8h-3z" />
              </svg>
            </button>
          </div>
        </div>
        <video id="vid" src="assets/Video.mp4">
          <track kind="captions" srclang="en" src="assets/subtitles.vtt">
        </video>
      </div>
      <section id="demos" class="invisible">
        <div class="blend-shapes">
          <ul class="blend-shapes-list" id="image-blend-shapes"></ul>
        </div>

        <div id="liveView" class="videoView">
          <button id="webcamButton" class="mdc-button mdc-button--raised">
            <span class="mdc-button__ripple"></span>
            <span class="mdc-button__label">ENABLE WEBCAM</span>
          </button>
          <div style="position: relative;">
            <video id="webcam" style="position: abso" autoplay playsinline></video>
            <canvas class="output_canvas" id="output_canvas" style="position: absolute; left: 0px; top: 0px;"></canvas>
          </div>
        </div>
        <div class="blend-shapes">
          <ul class="blend-shapes-list" id="video-blend-shapes"></ul>
        </div>
      </section>
    </div>
    <script type="module">
      const playPauseBtn = document.querySelector(".play-pause-btn")
      const theaterBtn = document.querySelector(".theater-btn")
      const fullScreenBtn = document.querySelector(".full-screen-btn")
      const miniPlayerBtn = document.querySelector(".mini-player-btn")
      const muteBtn = document.querySelector(".mute-btn")
      const captionsBtn = document.querySelector(".captions-btn")
      const speedBtn = document.querySelector(".speed-btn")
      const currentTimeElem = document.querySelector(".current-time")
      const totalTimeElem = document.querySelector(".total-time")
      const previewImg = document.querySelector(".preview-img")
      const thumbnailImg = document.querySelector(".thumbnail-img")
      const volumeSlider = document.querySelector(".volume-slider")
      const videoContainer = document.querySelector(".video-container")
      const timelineContainer = document.querySelector(".timeline-container")
      const video = document.querySelector("video")

      document.addEventListener("keydown", e => {
        const tagName = document.activeElement.tagName.toLowerCase()

        if (tagName === "input") return

        switch (e.key.toLowerCase()) {
          case " ":
            if (tagName === "button") return
          case "k":
            togglePlay()
            break
          case "f":
            toggleFullScreenMode()
            break
          case "t":
            toggleTheaterMode()
            break
          case "i":
            toggleMiniPlayerMode()
            break
          case "m":
            toggleMute()
            break
          case "arrowleft":
          case "j":
            skip(-5)
            break
          case "arrowright":
          case "l":
            skip(5)
            break
          case "c":
            toggleCaptions()
            break
        }
      })

      // Timeline
      timelineContainer.addEventListener("mousemove", handleTimelineUpdate)
      timelineContainer.addEventListener("mousedown", toggleScrubbing)
      document.addEventListener("mouseup", e => {
        if (isScrubbing) toggleScrubbing(e)
      })
      document.addEventListener("mousemove", e => {
        if (isScrubbing) handleTimelineUpdate(e)
      })

      let isScrubbing = false
      let wasPaused
      function toggleScrubbing(e) {
        const rect = timelineContainer.getBoundingClientRect()
        const percent = Math.min(Math.max(0, e.x - rect.x), rect.width) / rect.width
        isScrubbing = (e.buttons & 1) === 1
        videoContainer.classList.toggle("scrubbing", isScrubbing)
        if (isScrubbing) {
          wasPaused = video.paused
          video.pause()
        } else {
          video.currentTime = percent * video.duration
          if (!wasPaused) video.play()
        }

        handleTimelineUpdate(e)
      }

      function handleTimelineUpdate(e) {
        const rect = timelineContainer.getBoundingClientRect()
        const percent = Math.min(Math.max(0, e.x - rect.x), rect.width) / rect.width
        const previewImgNumber = Math.max(
          1,
          Math.floor((percent * video.duration) / 10)
        )
        const previewImgSrc = `assets/previewImgs/preview${previewImgNumber}.jpg`
        previewImg.src = previewImgSrc
        timelineContainer.style.setProperty("--preview-position", percent)

        if (isScrubbing) {
          e.preventDefault()
          thumbnailImg.src = previewImgSrc
          timelineContainer.style.setProperty("--progress-position", percent)
        }
      }

      // Playback Speed
      speedBtn.addEventListener("click", changePlaybackSpeed)

      function changePlaybackSpeed() {
        let newPlaybackRate = video.playbackRate + 0.25
        if (newPlaybackRate > 2) newPlaybackRate = 0.25
        video.playbackRate = newPlaybackRate
        speedBtn.textContent = `${newPlaybackRate}x`
      }

      // Captions
      const captions = video.textTracks[0]
      captions.mode = "hidden"

      captionsBtn.addEventListener("click", toggleCaptions)

      function toggleCaptions() {
        const isHidden = captions.mode === "hidden"
        captions.mode = isHidden ? "showing" : "hidden"
        videoContainer.classList.toggle("captions", isHidden)
      }

      // Duration
      video.addEventListener("loadeddata", () => {
        totalTimeElem.textContent = formatDuration(video.duration)
      })

      video.addEventListener("timeupdate", () => {
        currentTimeElem.textContent = formatDuration(video.currentTime)
        const percent = video.currentTime / video.duration
        timelineContainer.style.setProperty("--progress-position", percent)
      })

      const leadingZeroFormatter = new Intl.NumberFormat(undefined, {
        minimumIntegerDigits: 2,
      })
      function formatDuration(time) {
        const seconds = Math.floor(time % 60)
        const minutes = Math.floor(time / 60) % 60
        const hours = Math.floor(time / 3600)
        if (hours === 0) {
          return `${minutes}:${leadingZeroFormatter.format(seconds)}`
        } else {
          return `${hours}:${leadingZeroFormatter.format(
            minutes
          )}:${leadingZeroFormatter.format(seconds)}`
        }
      }

      function skip(duration) {
        video.currentTime += duration
      }

      // Volume
      muteBtn.addEventListener("click", toggleMute)
      volumeSlider.addEventListener("input", e => {
        video.volume = e.target.value
        video.muted = e.target.value === 0
      })

      function toggleMute() {
        video.muted = !video.muted
      }

      video.addEventListener("volumechange", () => {
        volumeSlider.value = video.volume
        let volumeLevel
        if (video.muted || video.volume === 0) {
          volumeSlider.value = 0
          volumeLevel = "muted"
        } else if (video.volume >= 0.5) {
          volumeLevel = "high"
        } else {
          volumeLevel = "low"
        }

        videoContainer.dataset.volumeLevel = volumeLevel
      })

      // View Modes
      theaterBtn.addEventListener("click", toggleTheaterMode)
      fullScreenBtn.addEventListener("click", toggleFullScreenMode)
      miniPlayerBtn.addEventListener("click", toggleMiniPlayerMode)

      function toggleTheaterMode() {
        videoContainer.classList.toggle("theater")
      }

      function toggleFullScreenMode() {
        if (document.fullscreenElement == null) {
          videoContainer.requestFullscreen()
        } else {
          document.exitFullscreen()
        }
      }

      function toggleMiniPlayerMode() {
        if (videoContainer.classList.contains("mini-player")) {
          document.exitPictureInPicture()
        } else {
          video.requestPictureInPicture()
        }
      }

      document.addEventListener("fullscreenchange", () => {
        videoContainer.classList.toggle("full-screen", document.fullscreenElement)
      })

      video.addEventListener("enterpictureinpicture", () => {
        videoContainer.classList.add("mini-player")
      })

      video.addEventListener("leavepictureinpicture", () => {
        videoContainer.classList.remove("mini-player")
      })

      // Play/Pause
      playPauseBtn.addEventListener("click", togglePlay)
      video.addEventListener("click", togglePlay)

      function togglePlay() {
        video.paused ? video.play() : video.pause()
      }

      video.addEventListener("play", () => {
        videoContainer.classList.remove("paused")
      })

      video.addEventListener("pause", () => {
        videoContainer.classList.add("paused")
      })


      import vision from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3';
      const {FaceLandmarker, FilesetResolver, DrawingUtils} = vision;
      const demosSection = document.getElementById('demos');
      const imageBlendShapes = document.getElementById('image-blend-shapes');
      const videoBlendShapes = document.getElementById('video-blend-shapes');

      let faceLandmarker;
      let runningMode = 'IMAGE';
      let enableWebcamButton;
      let webcamRunning = false;
      const videoWidth = 480;

      // Before we can use HandLandmarker class we must wait for it to finish
      // loading. Machine Learning models can be large and take a moment to
      // get everything needed to run.
      async function createFaceLandmarker() {
        const filesetResolver = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
        );
        faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
            delegate: 'GPU',
          },
          outputFaceBlendshapes: true,
          runningMode,
          numFaces: 1,
        });
        demosSection.classList.remove('invisible');
      }
      createFaceLandmarker();

      /********************************************************************
      // Demo 1: Grab a bunch of images from the page and detection them
      // upon click.
      ********************************************************************/

      // In this demo, we have put all our clickable images in divs with the
      // CSS class 'detectionOnClick'. Lets get all the elements that have
      // this class.
      const imageContainers = document.getElementsByClassName('detectOnClick');

      // Now let's go through all of these and add a click event listener.
      for (let imageContainer of imageContainers) {
        // Add event listener to the child element whichis the img element.
        imageContainer.children[0].addEventListener('click', handleClick);
      }

      // When an image is clicked, let's detect it and display results!
      async function handleClick(event) {
        if (!faceLandmarker) {
          console.log('Wait for faceLandmarker to load before clicking!');
          return;
        }

        if (runningMode === 'VIDEO') {
          runningMode = 'IMAGE';
          await faceLandmarker.setOptions({runningMode});
        }
        // Remove all landmarks drawed before
        const allCanvas = event.target.parentNode.getElementsByClassName('canvas');
        for (var i = allCanvas.length - 1; i >= 0; i--) {
          const n = allCanvas[i];
          n.parentNode.removeChild(n);
        }

        // We can call faceLandmarker.detect as many times as we like with
        // different image data each time. This returns a promise
        // which we wait to complete and then call a function to
        // print out the results of the prediction.
        const faceLandmarkerResult = faceLandmarker.detect(event.target);
        const canvas = document.createElement('canvas');
        canvas.setAttribute('class', 'canvas');
        canvas.setAttribute('width', event.target.naturalWidth + 'px');
        canvas.setAttribute('height', event.target.naturalHeight + 'px');
        canvas.style.left = '0px';
        canvas.style.top = '0px';
        canvas.style.width = `${event.target.width}px`;
        canvas.style.height = `${event.target.height}px`;

        event.target.parentNode.appendChild(canvas);
        const ctx = canvas.getContext('2d');
        const drawingUtils = new DrawingUtils(ctx);
        for (const landmarks of faceLandmarkerResult.faceLandmarks) {
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_TESSELATION, {
            color: '#C0C0C070',
            lineWidth: 1,
          });
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE, {
            color: '#FF3030',
          });
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW,
            {color: '#FF3030'}
          );
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYE, {
            color: '#30FF30',
          });
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW, {
            color: '#30FF30',
          });
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_FACE_OVAL, {
            color: '#E0E0E0',
          });
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LIPS, {
            color: '#E0E0E0',
          });
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS, {
            color: '#FF3030',
          });
          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS, {
            color: '#30FF30',
          });
        }
        drawBlendShapes(imageBlendShapes, faceLandmarkerResult.faceBlendshapes);
      }

      /********************************************************************
      // Demo 2: Continuously grab image from webcam stream and detect it.
      ********************************************************************/

      const vid = document.getElementById('webcam');
      const canvasElement = document.getElementById('output_canvas');

      const canvasCtx = canvasElement.getContext('2d');

      // Check if webcam access is supported.
      function hasGetUserMedia() {
        return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
      }

      // If webcam supported, add event listener to button for when user
      // wants to activate it.
      if (hasGetUserMedia()) {
        enableWebcamButton = document.getElementById('webcamButton');
        enableWebcamButton.addEventListener('click', enableCam);
      } else {
        console.warn('getUserMedia() is not supported by your browser');
      }

      // Enable the live webcam view and start detection.
      function enableCam(event) {
        if (!faceLandmarker) {
          console.log('Wait! faceLandmarker not loaded yet.');
          return;
        }

        if (webcamRunning === true) {
          webcamRunning = false;
          enableWebcamButton.innerText = 'ENABLE PREDICTIONS';
        } else {
          webcamRunning = true;
          enableWebcamButton.innerText = 'DISABLE PREDICTIONS';
        }

        // getUsermedia parameters.
        const constraints = {
          video: true,
        };

        // Activate the webcam stream.
        navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
          vid.srcObject = stream;
          vid.addEventListener('loadeddata', predictWebcam);
        });
      }

      let lastVideoTime = -1;
      let results = undefined;
      const drawingUtils = new DrawingUtils(canvasCtx);
      async function predictWebcam() {
        const radio = vid.videoHeight / vid.videoWidth;
        vid.style.width = videoWidth + 'px';
        vid.style.height = videoWidth * radio + 'px';
        canvasElement.style.width = videoWidth + 'px';
        canvasElement.style.height = videoWidth * radio + 'px';
        canvasElement.width = vid.videoWidth;
        canvasElement.height = vid.videoHeight;
        // Now let's start detecting the stream.
        if (runningMode === 'IMAGE') {
          runningMode = 'VIDEO';
          await faceLandmarker.setOptions({runningMode: runningMode});
        }
        let startTimeMs = performance.now();
        if (lastVideoTime !== vid.currentTime) {
          lastVideoTime = vid.currentTime;
          results = faceLandmarker.detectForVideo(vid, startTimeMs);
        }
        if (results.faceLandmarks) {
          for (const landmarks of results.faceLandmarks) {
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_TESSELATION,
              {color: '#C0C0C070', lineWidth: 1}
            );
            drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE, {
              color: '#FF3030',
            });
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW,
              {color: '#FF3030'}
            );
            drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYE, {
              color: '#30FF30',
            });
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW,
              {color: '#30FF30'}
            );
            drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_FACE_OVAL, {
              color: '#E0E0E0',
            });
            drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LIPS, {
              color: '#E0E0E0',
            });
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS,
              {color: '#FF3030'}
            );
            drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS, {
              color: '#30FF30',
            });
          }
        }
        drawBlendShapes(videoBlendShapes, results.faceBlendshapes);

        // Call this function again to keep predicting when the browser is ready.
        if (webcamRunning === true) {
          window.requestAnimationFrame(predictWebcam);
        }
      }

      function drawBlendShapes(el, blendShapes) {
        if (!blendShapes.length) {
          return;
        }

        let htmlMaker = '';
        blendShapes[0].categories.map((shape) => {
          htmlMaker += `
            <li class="blend-shapes-item">
              <span class="blend-shapes-label">${shape.displayName || shape.categoryName}</span>
              <span class="blend-shapes-value" style="width: calc(${
              +shape.score * 100
            }% - 120px)">${(+shape.score).toFixed(4)}</span>
            </li>
          `;
        });

        el.innerHTML = htmlMaker;
      }

    </script>
  </body>
</html>